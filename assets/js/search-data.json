{
  
    
        "post0": {
            "title": "Covid vs India",
            "content": "%of free vs paid | how many centers per state and who has best ratio against population? ( chart of top 5 and show it on map ) | at current allocation how many days will it take to vaccinate 18+? | what&#39;s ground reality for Key states like Delhi, Maharastra , Tamil Nadu | What&#39;s ground reality for populus states like UP, MP, | How does it fare around | Latest vaccine slots per district and State in India | Top 5 States Running behind on schedule | Top 5 States Running ahead of everyone else. | When can I latest find slots in Delhi, Bombay, Chennai and Bangalore for people between 18-45 | Credits : . Thanks to Github User @bhattbhavesh91 for Cowin app analysis notebook | Also thanks to Github User @AnujTiwari for Indian Shape file | . Source : . https://github.com/bhattbhavesh91/cowin-vaccination-slot-availability/blob/main/cowin-api-availability.ipynb | https://github.com/AnujTiwari/India-State-and-Country-Shapefile-Updated-Jan-2020 | . Get All libraries in place . import geopandas as gpd import pandas as pd import altair as alt import requests import json from collections import defaultdict from dataclasses import dataclass, asdict, field from datetime import datetime, timedelta from typing import List import uuid . Lets make a data class to store our geographical and vaccination data . @dataclass class District: district_id:int = None district_name:str = None state_id:int = None district_created_at: datetime = field(default_factory=datetime.now) @dataclass class Session: session_uuid:str = None date:datetime = None query_date:datetime= None available_capacity:int = None min_age_limit:int = None vaccine:str = None center_id:str = None district_id:str = None session_created_at: datetime = field(default_factory=datetime.now) @dataclass class Center: center_uuid:str = None center_id:int = None center_name:str = None state_name:str = None district_name:str = None block_name:str = None pincode:str = None lat:int = None lng:int = None from_hour:datetime = None to_hour:datetime = None fee_type:str = None district_id:str = None center_created_at: datetime = field(default_factory=datetime.now) @dataclass class NoSlotAvailable: district_id:str = None date:datetime = None no_slot_available_created_at: datetime = field(default_factory=datetime.now) . Lets call the API to get the populate geographical data . MOZILLA_HEADER = &#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36&#39; GET_DISTRICT_DATA_API_URL = &quot;https://cdn-api.co-vin.in/api/v2/admin/location/districts/{}&quot; GET_APOINTMENT_DATA_API_URL = &quot;https://cdn-api.co-vin.in/api/v2/appointment/sessions/public/calendarByDistrict?district_id={}&amp;date={}&quot; DISTRICTS = defaultdict(District) CENTERS = defaultdict(Center) SESSIONS = defaultdict(Session) NO_SLOT_AVAILABLE = [] INDIA_SHAPE_MAP = gpd.read_file(&#39;geo_data/india_state_boundary.shp&#39;) MAX_NUMBER_OF_STATES = 40 for state_code in range(1, MAX_NUMBER_OF_STATES): headers = {&#39;User-Agent&#39;: MOZILLA_HEADER} response = requests.get(GET_DISTRICT_DATA_API_URL.format(state_code), headers=headers) districts_data = json.loads(response.content) for district in districts_data[&#39;districts&#39;]: district_name = district[&#39;district_name&#39;] district_id = district[&#39;district_id&#39;] district = District(district_name = district_name, district_id = district_id , state_id=state_code) DISTRICTS[district_id] = district . # color = alt.condition(multi, # alt.Color(&#39;count&#39;, type=&#39;ordinal&#39;, # scale=alt.Scale(scheme=&#39;yellowgreenblue&#39;)), # alt.value(&#39;lightgray&#39;)) # hover = alt.selection(type=&#39;single&#39;, on=&#39;mouseover&#39;, nearest=True, # fields=[&#39;x&#39;, &#39;y&#39;])#Creating an altair map layerchoro = alt.Chart(INDIA_SHAPE_MAP).mark_geoshape( stroke=&#39;black&#39; ).encode( tooltip=[&#39;state&#39;,&#39;count&#39;] ).properties( width=650, height=800 )# Legend # c1 = alt.layer(choro).configure_legend( # orient = &#39;bottom-right&#39;, # direction = &#39;horizontal&#39;, # padding = 10, # rowPadding = 15 # )#Adding Labels # labels = alt.Chart(gdf).mark_text().encode( # longitude=&#39;x&#39;, # latitude=&#39;y&#39;, # text=&#39;count&#39;, # size=alt.value(8), # opacity=alt.value(0.6) # ) c2 = alt.Chart(INDIA_SHAPE_MAP).mark_geoshape( stroke=&#39;black&#39; ).encode( tooltip=[&#39;state&#39;,&#39;count&#39;] ).project( scale=100, ) # (c1+labels).configure_view(strokeWidth=0) layerchoro+ c2 . ValueError Traceback (most recent call last) ~/Library/Python/3.8/lib/python/site-packages/altair/vegalite/v4/api.py in to_dict(self, *args, **kwargs) 371 372 try: --&gt; 373 dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs) 374 except jsonschema.ValidationError: 375 dct = None ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in to_dict(self, validate, ignore, context) 323 result = _todict(self._args[0], validate=sub_validate, context=context) 324 elif not self._args: --&gt; 325 result = _todict( 326 {k: v for k, v in self._kwds.items() if k not in ignore}, 327 validate=sub_validate, ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in _todict(obj, validate, context) 58 return [_todict(v, validate, context) for v in obj] 59 elif isinstance(obj, dict): &gt; 60 return { 61 k: _todict(v, validate, context) 62 for k, v in obj.items() ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in &lt;dictcomp&gt;(.0) 59 elif isinstance(obj, dict): 60 return { &gt; 61 k: _todict(v, validate, context) 62 for k, v in obj.items() 63 if v is not Undefined ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in _todict(obj, validate, context) 56 return obj.to_dict(validate=validate, context=context) 57 elif isinstance(obj, (list, tuple, np.ndarray)): &gt; 58 return [_todict(v, validate, context) for v in obj] 59 elif isinstance(obj, dict): 60 return { ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in &lt;listcomp&gt;(.0) 56 return obj.to_dict(validate=validate, context=context) 57 elif isinstance(obj, (list, tuple, np.ndarray)): &gt; 58 return [_todict(v, validate, context) for v in obj] 59 elif isinstance(obj, dict): 60 return { ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in _todict(obj, validate, context) 54 &#34;&#34;&#34;Convert an object to a dict representation.&#34;&#34;&#34; 55 if isinstance(obj, SchemaBase): &gt; 56 return obj.to_dict(validate=validate, context=context) 57 elif isinstance(obj, (list, tuple, np.ndarray)): 58 return [_todict(v, validate, context) for v in obj] ~/Library/Python/3.8/lib/python/site-packages/altair/vegalite/v4/api.py in to_dict(self, *args, **kwargs) 371 372 try: --&gt; 373 dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs) 374 except jsonschema.ValidationError: 375 dct = None ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in to_dict(self, validate, ignore, context) 323 result = _todict(self._args[0], validate=sub_validate, context=context) 324 elif not self._args: --&gt; 325 result = _todict( 326 {k: v for k, v in self._kwds.items() if k not in ignore}, 327 validate=sub_validate, ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in _todict(obj, validate, context) 58 return [_todict(v, validate, context) for v in obj] 59 elif isinstance(obj, dict): &gt; 60 return { 61 k: _todict(v, validate, context) 62 for k, v in obj.items() ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in &lt;dictcomp&gt;(.0) 59 elif isinstance(obj, dict): 60 return { &gt; 61 k: _todict(v, validate, context) 62 for k, v in obj.items() 63 if v is not Undefined ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in _todict(obj, validate, context) 54 &#34;&#34;&#34;Convert an object to a dict representation.&#34;&#34;&#34; 55 if isinstance(obj, SchemaBase): &gt; 56 return obj.to_dict(validate=validate, context=context) 57 elif isinstance(obj, (list, tuple, np.ndarray)): 58 return [_todict(v, validate, context) for v in obj] ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in to_dict(self, validate, ignore, context) 323 result = _todict(self._args[0], validate=sub_validate, context=context) 324 elif not self._args: --&gt; 325 result = _todict( 326 {k: v for k, v in self._kwds.items() if k not in ignore}, 327 validate=sub_validate, ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in _todict(obj, validate, context) 58 return [_todict(v, validate, context) for v in obj] 59 elif isinstance(obj, dict): &gt; 60 return { 61 k: _todict(v, validate, context) 62 for k, v in obj.items() ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in &lt;dictcomp&gt;(.0) 59 elif isinstance(obj, dict): 60 return { &gt; 61 k: _todict(v, validate, context) 62 for k, v in obj.items() 63 if v is not Undefined ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in _todict(obj, validate, context) 56 return obj.to_dict(validate=validate, context=context) 57 elif isinstance(obj, (list, tuple, np.ndarray)): &gt; 58 return [_todict(v, validate, context) for v in obj] 59 elif isinstance(obj, dict): 60 return { ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in &lt;listcomp&gt;(.0) 56 return obj.to_dict(validate=validate, context=context) 57 elif isinstance(obj, (list, tuple, np.ndarray)): &gt; 58 return [_todict(v, validate, context) for v in obj] 59 elif isinstance(obj, dict): 60 return { ~/Library/Python/3.8/lib/python/site-packages/altair/utils/schemapi.py in _todict(obj, validate, context) 54 &#34;&#34;&#34;Convert an object to a dict representation.&#34;&#34;&#34; 55 if isinstance(obj, SchemaBase): &gt; 56 return obj.to_dict(validate=validate, context=context) 57 elif isinstance(obj, (list, tuple, np.ndarray)): 58 return [_todict(v, validate, context) for v in obj] ~/Library/Python/3.8/lib/python/site-packages/altair/vegalite/v4/schema/channels.py in to_dict(self, validate, ignore, context) 38 elif not (type_in_shorthand or type_defined_explicitly): 39 if isinstance(context.get(&#39;data&#39;, None), pd.DataFrame): &gt; 40 raise ValueError(&#34;{} encoding field is specified without a type; &#34; 41 &#34;the type cannot be inferred because it does not &#34; 42 &#34;match any column in the data.&#34;.format(shorthand)) ValueError: state encoding field is specified without a type; the type cannot be inferred because it does not match any column in the data. . alt.LayerChart(...) . DISTRICT_DF = pd.DataFrame.from_dict([asdict(district) for district in DISTRICTS.values()]) . Lets now call actual api to get slots . MAX_DAYS = 7 #This step takes loads of time def get_days_in_future_from_today(): base = datetime.today() date_list = [base + timedelta(days=x) for x in range(MAX_DAYS)] return [x.strftime(&quot;%d-%m-%Y&quot;) for x in date_list] for district_id in DISTRICTS.keys(): print(&quot;District {}&quot;.format(district_id)) for slot_date in get_days_in_future_from_today(): URL = GET_APOINTMENT_DATA_API_URL.format(district_id, slot_date) response = requests.get(URL) if response.ok: resp_json = response.json() if resp_json[&quot;centers&quot;]: for center in resp_json[&quot;centers&quot;]: center_uuid = str(uuid.uuid4()) center_id = center[&quot;center_id&quot;] center_name = center[&quot;name&quot;] CENTERS[center_uuid] = Center(center_uuid=center_uuid, center_id=center_id, center_name=center_name, lat=center[&quot;lat&quot;], lng=center[&quot;long&quot;], from_hour=center[&quot;from&quot;], to_hour=center[&quot;to&quot;], district_id=district_id, state_name=center[&quot;state_name&quot;], district_name=center[&quot;district_name&quot;], block_name=center[&quot;block_name&quot;], pincode=center[&quot;pincode&quot;], fee_type=center[&quot;fee_type&quot;]) for session in center[&quot;sessions&quot;]: session_id = session[&quot;session_id&quot;] SESSIONS[session_id] = Session(session_uuid=session_id, date=session[&quot;date&quot;], query_date=slot_date, available_capacity=session[&quot;available_capacity&quot;], min_age_limit=session[&quot;min_age_limit&quot;], vaccine=session[&quot;vaccine&quot;], district_id=district_id, center_id=center_id) else: NO_SLOT_AVAILABLE.append(NoSlotAvailable(district_id=district_id, date=slot_date)) # print(&quot;No slot on {} in district {}&quot;.format(slot_date, district_id)) . CENTER_DF = pd.DataFrame.from_dict([asdict(district) for district in CENTERS.values()]) SESSION_DF = pd.DataFrame.from_dict([asdict(session) for session in SESSIONS.values()]) NO_SLOT_AVAILABLE_DF = pd.DataFrame.from_dict([asdict(no_slot_available) for no_slot_available in NO_SLOT_AVAILABLE]) . NO_SLOT_AVAILABLE_DF.head() . district_id date no_slot_available_created_at . 0 5 | 04-05-2021 | 2021-05-03 16:22:33.578494 | . 1 5 | 05-05-2021 | 2021-05-03 16:22:33.744831 | . 2 5 | 06-05-2021 | 2021-05-03 16:22:33.859553 | . 3 5 | 07-05-2021 | 2021-05-03 16:22:33.970119 | . 4 5 | 08-05-2021 | 2021-05-03 16:22:34.321653 | . SESSION_DF.head()[[&quot;date&quot;,&quot;available_capacity&quot;,&quot;vaccine&quot;,&quot;min_age_limit&quot;]] . date available_capacity vaccine min_age_limit . 0 03-05-2021 | 49.0 | | 45 | . 1 04-05-2021 | 50.0 | | 45 | . 2 05-05-2021 | 50.0 | | 45 | . 3 06-05-2021 | 50.0 | | 45 | . 4 08-05-2021 | 49.0 | | 45 | . CENTER_DF.head()[[&quot;center_name&quot;,&quot;state_name&quot;,&quot;district_name&quot;,&quot;fee_type&quot;]] . center_name state_name district_name fee_type . 0 BJR Hospital | Andaman and Nicobar Islands | Nicobar | Free | . 1 MI Room DHQ 10 | Andaman and Nicobar Islands | Nicobar | Free | . 2 Campbellbay PHC | Andaman and Nicobar Islands | Nicobar | Free | . 3 Nancowry CHC | Andaman and Nicobar Islands | Nicobar | Free | . 4 SMC 37 WING | Andaman and Nicobar Islands | Nicobar | Free | . DISTRICT_DF.head() . district_id district_name state_id district_created_at . 0 3 | Nicobar | 1 | 2021-05-03 16:22:15.927874 | . 1 1 | North and Middle Andaman | 1 | 2021-05-03 16:22:15.927885 | . 2 2 | South Andaman | 1 | 2021-05-03 16:22:15.927887 | . 3 9 | Anantapur | 2 | 2021-05-03 16:22:17.377390 | . 4 10 | Chittoor | 2 | 2021-05-03 16:22:17.377401 | . session_center_merged_df = pd.merge(SESSION_DF, CENTER_DF, on=&quot;center_id&quot;) session_center_district_df = pd.merge(session_center_merged_df, DISTRICT_DF, left_on=&#39;district_id_x&#39;, right_on=&quot;district_id&quot;) . session_center_district_df.to_csv(&quot;vaccination_slot_data.csv&quot;) session_center_district_df[[&quot;date&quot;,&quot;center_name&quot;,&quot;state_name&quot;,&quot;district_name_x&quot;,&quot;fee_type&quot;]] . date center_name state_name district_name_x fee_type . 0 03-05-2021 | BJR Hospital | Andaman and Nicobar Islands | Nicobar | Free | . 1 03-05-2021 | BJR Hospital | Andaman and Nicobar Islands | Nicobar | Free | . 2 03-05-2021 | BJR Hospital | Andaman and Nicobar Islands | Nicobar | Free | . 3 03-05-2021 | BJR Hospital | Andaman and Nicobar Islands | Nicobar | Free | . 4 03-05-2021 | BJR Hospital | Andaman and Nicobar Islands | Nicobar | Free | . ... ... | ... | ... | ... | ... | . 1251756 04-05-2021 | Government Hospital Diu | Daman and Diu | Diu | Free | . 1251757 04-05-2021 | Government Hospital Diu | Daman and Diu | Diu | Free | . 1251758 05-05-2021 | Government Hospital Diu | Daman and Diu | Diu | Free | . 1251759 05-05-2021 | Government Hospital Diu | Daman and Diu | Diu | Free | . 1251760 05-05-2021 | Government Hospital Diu | Daman and Diu | Diu | Free | . 1251761 rows × 5 columns . session_center_district_df[[&#39;date&#39;, &#39;state_name&#39;]].groupby(&#39;state_name&#39;).apply(lambda x : x.sort_values(by = &#39;date&#39;, ascending = True).head(3).reset_index(drop = True)) . date state_name . state_name . Andaman and Nicobar Islands 0 03-05-2021 | Andaman and Nicobar Islands | . 1 03-05-2021 | Andaman and Nicobar Islands | . 2 03-05-2021 | Andaman and Nicobar Islands | . Andhra Pradesh 0 03-05-2021 | Andhra Pradesh | . 1 03-05-2021 | Andhra Pradesh | . ... ... ... | ... | . Uttarakhand 1 03-05-2021 | Uttarakhand | . 2 03-05-2021 | Uttarakhand | . West Bengal 0 03-05-2021 | West Bengal | . 1 03-05-2021 | West Bengal | . 2 03-05-2021 | West Bengal | . 111 rows × 2 columns . sessions_for_below_45 = session_center_district_df [session_center_district_df[&quot;min_age_limit&quot;] &lt;45] sessions_for_below_45_free_fee_type_count = len(sessions_for_below_45[sessions_for_below_45[&quot;fee_type&quot;]==&quot;Free&quot;]) sessions_for_below_45_not_free_fee_type_count = len(sessions_for_below_45) - sessions_for_below_45_free_fee_type_count sessions_for_below_45_not_free_fee_type_count, sessions_for_below_45_free_fee_type_count source = pd.DataFrame({ &quot;y&quot;:[&quot;Free Vaccines Centers&quot;,&quot;Paid Vaccines Centers&quot;], &quot;x&quot;:[sessions_for_below_45_not_free_fee_type_count,sessions_for_below_45_free_fee_type_count] }) bars = alt.Chart(source).transform_joinaggregate( TotalX=&#39;sum(x)&#39;, ).transform_calculate( PercentOfTotal=&quot;datum.x / datum.TotalX&quot; ).mark_bar( cornerRadiusTopLeft=3, cornerRadiusTopRight=3 ).encode( alt.X(&#39;PercentOfTotal:Q&#39;, axis=alt.Axis(format=&#39;.0%&#39;)), y=&#39;y&#39;, ) text = bars.mark_text( align=&#39;left&#39;, baseline=&#39;middle&#39;, dx=3 # Nudges text to right so it doesn&#39;t appear on top of the bar ).encode( text=&#39;x&#39; ) (bars+text).properties(height=200) . session_count = sessions_for_below_45.groupby(&quot;state_name&quot;)[[&quot;state_name&quot;]].agg([&quot;count&quot;]).sort_values((&#39;state_name&#39;, &#39;count&#39;),ascending=False) session_count . state_name . count . state_name . Delhi 3368 | . Uttar Pradesh 2973 | . Gujarat 2619 | . Maharashtra 2254 | . Haryana 1748 | . Odisha 836 | . Jammu and Kashmir 729 | . Rajasthan 620 | . Punjab 311 | . Tamil Nadu 163 | . Uttarakhand 150 | . Karnataka 125 | . Goa 36 | . Chhattisgarh 22 | . Jharkhand 11 | . West Bengal 10 | . Madhya Pradesh 8 | . Kerala 8 | . Lakshadweep 6 | . Himachal Pradesh 2 | . Ladakh 1 | .",
            "url": "https://shashanksingh.github.io/blog_redux/dfs/jupyter/python/2021/04/30/covid-vacctionations-slots-in-india.html",
            "relUrl": "/dfs/jupyter/python/2021/04/30/covid-vacctionations-slots-in-india.html",
            "date": " • Apr 30, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Covid vs The World - Part II",
            "content": "During this madness of ever locking down and then un-locked down&#39;s, I have been wondering how the world has been affected by the madness of it all. So I did, what I did best, try searching for some answers by experimenting with data that I found online. . Probably not the best way, but served as a good proxy for me to form a mental picture of how the world is dragging itself through 2020. . On more positive news with vaccine just around the corner, there is finally light at end of the tunnel. . So to cut short to the chase, I am using google trend and timelines from matplotlib to see what correlations I could find. The adage applies here &quot;correlation is not causation&quot;, so take it with pinch of salt. . ticket_google_trend_per_week_df = pd.DataFrame(ticket_google_trend_per_week, columns= [&quot;week&quot;,&quot;ticket&quot;, &quot;vaccine&quot;, &quot;stream&quot;]) ticket_google_trend_per_week_df.head() . week ticket vaccine stream . 0 2019-11-17 | 66 | 12 | 67 | . 1 2019-11-24 | 66 | 10 | 67 | . 2 2019-12-01 | 67 | 11 | 72 | . 3 2019-12-08 | 65 | 10 | 61 | . 4 2019-12-15 | 65 | 10 | 69 | . ticket_google_trend_per_week_melted_df = pd.melt(ticket_google_trend_per_week_df,id_vars=[&quot;week&quot;],var_name=[&quot;types&quot;]) alt.Chart(ticket_google_trend_per_week_melted_df).mark_area(opacity=0.3).encode( x = &#39;week&#39;, y = alt.Y(&quot;value:Q&quot;, stack=None), color=&#39;types&#39;, ).properties( height=400, width=850, ) . So my inference was the moment Covid-19 hit prime time globally, people stopped looking for tickets, top search items being: the ticket price, ticket booking, train ticket, online ticket, ticket flight, etc. Consequently, a global lockdown let everyone focus more on vaccine news and the top search item being covid vaccine and started munching on online stream whatever they could, top search item being: live stream, stream on, how to stream, tv stream, etc. . I pulled data from here. . The date all this started happening, 1st of march 2020. .",
            "url": "https://shashanksingh.github.io/blog_redux/dfs/jupyter/python/2020/11/01/covid-impact-on-industries-based-on-google-trends.html",
            "relUrl": "/dfs/jupyter/python/2020/11/01/covid-impact-on-industries-based-on-google-trends.html",
            "date": " • Nov 1, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Depth First Search : Planning a vacation",
            "content": "What possible ways are there to reach from DARWIN to SYDNEY ? . import requests import pandas as pd import json r = requests.get(&#39;https://data.gov.au/data/api/3/action/datastore_search?resource_id=677d307f-6a1f-4de4-9b85-5e1aa7074423&#39;) data_json = json.loads(r.text) data = pd.DataFrame(data_json[&quot;result&quot;][&quot;records&quot;],columns=[&quot;City1&quot;,&quot;City2&quot;,&quot;Aircraft_Trips&quot;]) . pd.set_option(&quot;display.max_rows&quot;, 10) data.groupby(by = [&quot;City1&quot;,&quot;City2&quot;]).count() . Aircraft_Trips . City1 City2 . ADELAIDE ALICE SPRINGS 2 | . BRISBANE 3 | . DARWIN 4 | . GOLD COAST 4 | . MELBOURNE 1 | . ... ... ... | . PORT MACQUARIE SYDNEY 1 | . PROSERPINE SYDNEY 1 | . SUNSHINE COAST MELBOURNE 1 | . SYDNEY TOWNSVILLE 2 | . WAGGA WAGGA 1 | . 49 rows × 1 columns . #first initizlie it unique_columns = list(set(data.City1.unique()).union(set(data.City2.unique()))) adjacency_matrix = [[0 for columns in range(len(unique_columns))] for row in range(len(unique_columns))] adjacency_list = [] #Lets create adjcacncey network # fill in the values for ind in data.index: city1_index = unique_columns.index(data[&#39;City1&#39;][ind]) city2_index = unique_columns.index(data[&#39;City2&#39;][ind]) adjacency_matrix[city1_index][city2_index] = 1 adjacency_matrix[city2_index][city1_index] = 1 draw_graph_from_adjacency_matrix(adjacency_matrix) . from typing import List TOTAL_VERTICES = len(adjacency_list) TOTAL_NODES = len(unique_columns) class PathFinder(): def __init__(self, adjacency_matrix : List[List[int]])-&gt; None: self.adjacency_matrix = adjacency_matrix def all_paths_helper(self, city_name_from:str , city_name_to:str, visited: List[bool], path: List[str], all_paths: List[List[str]]) -&gt; str: city_name_from_index = unique_columns.index(city_name_from) visited[city_name_from_index] = True path.append(city_name_from) if city_name_from == city_name_to : all_paths.append(path.copy()) # print(path) else: neighbours = self.adjacency_matrix[city_name_from_index:city_name_from_index+1][0] for index in range(len(neighbours)): if neighbours[index] == 1: neighbour = unique_columns[index] if visited[index] == False: self.all_paths_helper(neighbour, city_name_to, visited, path, all_paths) #for all neighbours of this path call ourselbes path.pop() visited[city_name_from_index]= False def all_paths(self, city_name_from:str , city_name_to:str) -&gt; str: if not (city_name_from in unique_columns and city_name_to in unique_columns): return &quot;Incorrect City&quot; visited = [False] * TOTAL_NODES path = [] all_paths = [] self.all_paths_helper(city_name_from , city_name_to, visited, path , all_paths) return all_paths pf = PathFinder(adjacency_matrix) all_paths = pf.all_paths(&quot;DARWIN&quot;, &quot;SYDNEY&quot;) . df_all_paths = pd.DataFrame(all_paths) df_all_paths . 0 1 2 3 4 5 6 7 8 . 0 DARWIN | MELBOURNE | SYDNEY | None | None | None | None | None | None | . 1 DARWIN | MELBOURNE | CANBERRA | SYDNEY | None | None | None | None | None | . 2 DARWIN | MELBOURNE | CANBERRA | BRISBANE | PROSERPINE | SYDNEY | None | None | None | . 3 DARWIN | MELBOURNE | CANBERRA | BRISBANE | SYDNEY | None | None | None | None | . 4 DARWIN | MELBOURNE | CANBERRA | BRISBANE | CAIRNS | SYDNEY | None | None | None | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 359 DARWIN | ADELAIDE | PERTH | BRISBANE | CAIRNS | MELBOURNE | ALICE SPRINGS | SYDNEY | None | . 360 DARWIN | ADELAIDE | PERTH | BRISBANE | CAIRNS | MELBOURNE | NEWCASTLE | GOLD COAST | SYDNEY | . 361 DARWIN | ADELAIDE | PERTH | BRISBANE | CAIRNS | MELBOURNE | GOLD COAST | SYDNEY | None | . 362 DARWIN | ADELAIDE | PERTH | BRISBANE | CAIRNS | SYDNEY | None | None | None | . 363 DARWIN | ADELAIDE | PERTH | BRISBANE | TOWNSVILLE | SYDNEY | None | None | None | . 364 rows × 9 columns .",
            "url": "https://shashanksingh.github.io/blog_redux/dfs/jupyter/python/2020/10/03/dfs.html",
            "relUrl": "/dfs/jupyter/python/2020/10/03/dfs.html",
            "date": " • Oct 3, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Covid vs The World - Part I",
            "content": "%matplotlib inline import matplotlib.pyplot as plt import pandas as pd #### -- Step 1 (Download data)- URL_DATASET = r&#39;https://raw.githubusercontent.com/datasets/covid-19/master/data/countries-aggregated.csv&#39; df = pd.read_csv(URL_DATASET) df[&#39;NewCases&#39;] = df[&#39;Confirmed&#39;] - df[&#39;Confirmed&#39;].shift(1) #### -- Step 2 (Select data for India)- df_india = df[df[&#39;Country&#39;] == &#39;India&#39;] df_india.tail(5) . Date Country Confirmed Recovered Deaths NewCases . 25275 2020-11-28 | India | 9392919 | 8802267 | 136696 | 41810.0 | . 25276 2020-11-29 | India | 9431691 | 8847600 | 137139 | 38772.0 | . 25277 2020-11-30 | India | 9462809 | 8889585 | 137621 | 31118.0 | . 25278 2020-12-01 | India | 9499413 | 8932647 | 138122 | 36604.0 | . 25279 2020-12-02 | India | 9534964 | 8973373 | 138648 | 35551.0 | . #### -- Step 3 (Plot data)- # Increase size of plot plt.rcParams[&quot;figure.figsize&quot;]=20,14 # Remove if not on Jupyter df_india.plot( x = &#39;Date&#39;, y = &#39;Confirmed&#39;, color = &#39;blue&#39;) df_india.plot( x = &#39;Date&#39;, y = &#39;NewCases&#39;, color = &#39;blue&#39;) . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; .",
            "url": "https://shashanksingh.github.io/blog_redux/covid/jupyter/python/2020/09/20/covid-impact.html",
            "relUrl": "/covid/jupyter/python/2020/09/20/covid-impact.html",
            "date": " • Sep 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "",
          "url": "https://shashanksingh.github.io/blog_redux/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://shashanksingh.github.io/blog_redux/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}