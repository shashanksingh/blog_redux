{
  
    
        "post0": {
            "title": "Covid vs The World - Part II",
            "content": "I have been thinking to understand the true impact of industries. .",
            "url": "https://shashanksingh.github.io/blog_redux/dfs/jupyter/python/2020/11/01/covid-impact-on-industries-based-on-google-trends.html",
            "relUrl": "/dfs/jupyter/python/2020/11/01/covid-impact-on-industries-based-on-google-trends.html",
            "date": " • Nov 1, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Depth First Search : Planning a vacation",
            "content": "Problem statement . Depth First Search . What possible ways are there to reach from DARWIN to SYDNEY ? . import requests import pandas as pd import json r = requests.get(&#39;https://data.gov.au/data/api/3/action/datastore_search?resource_id=677d307f-6a1f-4de4-9b85-5e1aa7074423&#39;) data_json = json.loads(r.text) data = pd.DataFrame(data_json[&quot;result&quot;][&quot;records&quot;],columns=[&quot;City1&quot;,&quot;City2&quot;,&quot;Aircraft_Trips&quot;]) . /Users/shashanksingh/.pyenv/versions/3.9.0/envs/blog_redux/lib/python3.9/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError. warnings.warn(msg) . pd.set_option(&quot;display.max_rows&quot;, 10) data.groupby(by = [&quot;City1&quot;,&quot;City2&quot;]).count() . Aircraft_Trips . City1 City2 . ADELAIDE ALICE SPRINGS 2 | . BRISBANE 3 | . DARWIN 4 | . GOLD COAST 4 | . MELBOURNE 1 | . ... ... ... | . PORT MACQUARIE SYDNEY 1 | . PROSERPINE SYDNEY 1 | . SUNSHINE COAST MELBOURNE 1 | . SYDNEY TOWNSVILLE 2 | . WAGGA WAGGA 1 | . 49 rows × 1 columns . #first initizlie it unique_columns = list(set(data.City1.unique()).union(set(data.City2.unique()))) adjacency_matrix = [[0 for columns in range(len(unique_columns))] for row in range(len(unique_columns))] adjacency_list = [] #Lets create adjcacncey network # fill in the values for ind in data.index: city1_index = unique_columns.index(data[&#39;City1&#39;][ind]) city2_index = unique_columns.index(data[&#39;City2&#39;][ind]) adjacency_matrix[city1_index][city2_index] = 1 adjacency_matrix[city2_index][city1_index] = 1 draw_graph_from_adjacency_matrix(adjacency_matrix) . from typing import List TOTAL_VERTICES = len(adjacency_list) TOTAL_NODES = len(unique_columns) class PathFinder(): def __init__(self, adjacency_matrix : List[List[int]])-&gt; None: self.adjacency_matrix = adjacency_matrix def all_paths_helper(self, city_name_from:str , city_name_to:str, visited: List[bool], path: List[str], all_paths: List[List[str]]) -&gt; str: city_name_from_index = unique_columns.index(city_name_from) visited[city_name_from_index] = True path.append(city_name_from) if city_name_from == city_name_to : all_paths.append(path.copy()) # print(path) else: neighbours = self.adjacency_matrix[city_name_from_index:city_name_from_index+1][0] for index in range(len(neighbours)): if neighbours[index] == 1: neighbour = unique_columns[index] if visited[index] == False: self.all_paths_helper(neighbour, city_name_to, visited, path, all_paths) #for all neighbours of this path call ourselbes path.pop() visited[city_name_from_index]= False def all_paths(self, city_name_from:str , city_name_to:str) -&gt; str: if not (city_name_from in unique_columns and city_name_to in unique_columns): return &quot;Incorrect City&quot; visited = [False] * TOTAL_NODES path = [] all_paths = [] self.all_paths_helper(city_name_from , city_name_to, visited, path , all_paths) return all_paths pf = PathFinder(adjacency_matrix) all_paths = pf.all_paths(&quot;DARWIN&quot;, &quot;SYDNEY&quot;) . df_all_paths = pd.DataFrame(all_paths) . .",
            "url": "https://shashanksingh.github.io/blog_redux/dfs/jupyter/python/2020/10/03/dfs.html",
            "relUrl": "/dfs/jupyter/python/2020/10/03/dfs.html",
            "date": " • Oct 3, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Covid vs The World - Part I",
            "content": "%matplotlib inline import matplotlib.pyplot as plt import pandas as pd #### -- Step 1 (Download data)- URL_DATASET = r&#39;https://raw.githubusercontent.com/datasets/covid-19/master/data/countries-aggregated.csv&#39; df = pd.read_csv(URL_DATASET) df[&#39;NewCases&#39;] = df[&#39;Confirmed&#39;] - df[&#39;Confirmed&#39;].shift(1) #### -- Step 2 (Select data for India)- df_india = df[df[&#39;Country&#39;] == &#39;India&#39;] df_india.tail(5) . Date Country Confirmed Recovered Deaths NewCases . 25115 2020-11-26 | India | 9309787 | 8718517 | 135715 | 43082.0 | . 25116 2020-11-27 | India | 9351109 | 8759969 | 136200 | 41322.0 | . 25117 2020-11-28 | India | 9392919 | 8802267 | 136696 | 41810.0 | . 25118 2020-11-29 | India | 9431691 | 8847600 | 137139 | 38772.0 | . 25119 2020-11-30 | India | 9462809 | 8889585 | 137621 | 31118.0 | . #### -- Step 3 (Plot data)- # Increase size of plot plt.rcParams[&quot;figure.figsize&quot;]=20,14 # Remove if not on Jupyter df_india.plot( x = &#39;Date&#39;, y = &#39;Confirmed&#39;, color = &#39;blue&#39;) df_india.plot( x = &#39;Date&#39;, y = &#39;NewCases&#39;, color = &#39;blue&#39;) . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; .",
            "url": "https://shashanksingh.github.io/blog_redux/covid/jupyter/python/2020/09/20/covid-impact.html",
            "relUrl": "/covid/jupyter/python/2020/09/20/covid-impact.html",
            "date": " • Sep 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "",
          "url": "https://shashanksingh.github.io/blog_redux/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://shashanksingh.github.io/blog_redux/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}